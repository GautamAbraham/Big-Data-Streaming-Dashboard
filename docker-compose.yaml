services:

  # Frontend loads after all data pipeline components are ready
  frontend:
    build:
      context: ./front_end
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    env_file:
      - ./front_end/.env
    depends_on:
      kafka:
        condition: service_healthy
      flink-jobmanager:
        condition: service_started
      flink-taskmanager-1:
        condition: service_started
      flink-processor:
        condition: service_started
      data-provider:
        condition: service_started
      backend:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_METADATA_LOG_DIR: /var/lib/kafka/data
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 4  # Reduced for 8GB RAM - matches source parallelism
      KAFKA_LOG_RETENTION_HOURS: 12  # Reduced retention for memory efficiency
      KAFKA_LOG_SEGMENT_BYTES: 536870912  # 512MB log segments (reduced)
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 5000  # Flush every 5k messages
      KAFKA_LOG_FLUSH_INTERVAL_MS: 2000  # Or every 2 seconds
      CLUSTER_ID: zrdRC-2GRYG5kygU-gcIEw
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9092"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1280M
        reservations:
          cpus: '1.0'
          memory: 896M

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  data-provider:
    build:
      context: ./data_provider
      dockerfile: Dockerfile
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      CONFIG_FILE: /app/config.ini
    volumes:
      - ./data_provider:/app
      - ./data_provider/safecast_data:/app/safecast_data
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M

  flink-jobmanager:
    build:
      context: ./flink_process
      dockerfile: Dockerfile
    container_name: jobmanager
    hostname: jobmanager
    ports:
      - "8081:8081"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 3
        jobmanager.memory.process.size: 1024m
        taskmanager.memory.process.size: 2048m
        execution.checkpointing.interval: 2min
        state.backend.incremental: true
        taskmanager.memory.managed.fraction: 0.4
        state.backend: rocksdb
        execution.runtime-mode: streaming
    command: jobmanager
    depends_on:
      kafka:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1280M
        reservations:
          cpus: '0.75'
          memory: 1024M

  flink-taskmanager-1:
    build:
      context: ./flink_process
      dockerfile: Dockerfile
    container_name: flink-taskmanager-1
    depends_on:
      flink-jobmanager:
        condition: service_started
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 3
        jobmanager.memory.process.size: 1024m
        taskmanager.memory.process.size: 2048m
        execution.checkpointing.enabled: true
        execution.checkpointing.interval: 2min
        state.backend.incremental: true
        state.backend: rocksdb
        taskmanager.memory.managed.fraction: 0.4
        execution.runtime-mode: streaming
    command: taskmanager
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2560M
        reservations:
          cpus: '1.5'
          memory: 2048M

  # flink-taskmanager-2:
  #   build:
  #     context: ./flink_process
  #     dockerfile: Dockerfile
  #   container_name: flink-taskmanager-2
  #   depends_on:
  #     flink-jobmanager:
  #       condition: service_started
  #   environment:
  #     - JOB_MANAGER_RPC_ADDRESS=jobmanager
  #     - TASK_MANAGER_NUMBER_OF_TASK_SLOTS=4
  #     - TASK_MANAGER_MEMORY_PROCESS_SIZE=2048m
  #     - TASK_MANAGER_MEMORY_FRAMEWORK_HEAP_SIZE=128m
  #     - TASK_MANAGER_MEMORY_TASK_HEAP_SIZE=1536m
  #     - TASK_MANAGER_MEMORY_MANAGED_SIZE=384m
  #   command: taskmanager
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '2.5'
  #         memory: 1024M
  #       reservations:
  #         cpus: '2.0'
  #         memory: 768M

  flink-processor:
    build:
      context: ./flink_process
      dockerfile: Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
      flink-jobmanager:
        condition: service_started
    volumes:
      - ./flink_process:/opt/flink/usrlib

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    depends_on:
      flink-jobmanager:
        condition: service_started
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 384M
        reservations:
          cpus: '0.5'
          memory: 256M
volumes:
  kafka_data: